---
title: ""
permalink: "/dlopt2025/"
layout: page
---

## PKU Class 2025 Fall: Optimizaiton for Deep Learning

Instructor: **Kun Yuan** (kunyuan@pku.edu.cn) <br>

Teaching assistants: 
- **Yilong Song** (2301213059@pku.edu.cn) [Leading Teaching Assistant] <br> 
- **Mian Xiao** (xiaom@stu.pku.edu.cn) <br>
- **Ruoxi Yu** (2301111452@stu.pku.edu.cn) <br>

Classroom: 3pm - 6pm Tuesday, 理教206

Office hour: 4pm - 5pm Thursday, 静园六院220

## References
Martin Jaggi and Nicolas Flammarion, *[Optimization for Machine Learning](https://github.com/epfml/OptML_course)*, EPFL Class CS-439 <br>
Chris De Sa, *[Advanced Machine Learning Systems](https://www.cs.cornell.edu/courses/cs6787/2021fa/)*, Cornell CS6787 <br>
Zaiwen Wen, *[Optimization Methods](http://faculty.bicmr.pku.edu.cn/~wenzw/opt-2024-fall.html)*, PKU 2024 Fall<br>
Kun Yuan, *[Introduction to LLM](https://kunyuan827.github.io/llm2025/)*, PKU 2025 Spring

## Announcement

<!--
3. <span style="background-color:#f9f9c5;">The lecture scheduled for December 2 has been canceled. We will make it up on December 11, from 6:40 p.m. to 9:30 p.m., in Room 403 of the Third Teaching Building (三教403)
-->

1. <span style="background-color:#f9f9c5;">The lecture scheduled for November 25 has been canceled. It will be rescheduled for November 28, from 3:10 p.m. to 6:00 p.m., in Room 403 of the Third Teaching Building (三教403).</span>

2. <span style="background-color:#f9f9c5;">The Midterm Exam is scheduled on November 4.</span>

3. <span style="background-color:#f9f9c5;">The lecture scheduled for October 28 has been canceled. It will be rescheduled for October 31, from 3:10 p.m. to 6:00 p.m., in Room 理教306.</span>

4. <span style="background-color:#f9f9c5;">The lecture scheduled for September 9 has been canceled. It will be rescheduled for September 18, from 6:40 p.m. to 9:30 p.m., in Room 407 of the Third Teaching Building (三教407).</span>

## Materials

### Lecture 1: Introduction <br>
- Warm up: Preliminary [[Notes]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/notes_ch0.pdf) <br>
- Part   I: Introduction to Deep Learning [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/Intro1.pdf) <br> 
- Part  II: Introduction to LLM [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2025/Intro2.pdf)

### Lecture 2: Basics in Machine Learning and Langugae Models <br>
- Part   I: Basics in Machine Learning [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/02_MLBasics.pdf) <br>
- Part  II: Basics in Language models [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/03_langmodel.pdf)

### Lecture 3: Transformer <br>
- Part I: Seq2Seq; Attention; Transformer [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/04_transformer.pdf)
- Part II: Parameters, Computations, and Memory Costs in Transformer [[Slides01]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/04_Parameter_analysis.pdf) [[Slides02]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/12_memory_analysis.pdf)

### Lecture 4: Some LLM Models <br>
- Teacher forcing; Pretrain and Finetuning; BERT; GPTs [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/LLM2025/11_Bert_and_GPT.pdf)
- DeepSeek [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/19_Parallesm.pdf)

### Lecture 5: Gradient Descent <br>
- Convex set; Convex functions; Convex problems; Gradient descent [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/LLM2025/03_GD.pdf) [[Notes]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/LLM2025/notes_1.pdf)
- Forward-backward propagation [[Notes]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/LLM2025/notes_2.pdf)

### Lecture 6: Accelerated Gradient Descent <br>
- Momentum gradient descent; Nesterov acceleration; Anderson acceleration [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/08_ACC_GD.pdf) [[Notes]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/notes_ch3.pdf) <br>

### Lecture 7: Stochastic Gradient Descent <br>
- Stochastic gradient descent [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/06_SGD.pdf) [[Notes]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/Notes_SGD.pdf)  <br>
- Sampling in SGD [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/07_SGD_sampling.pdf)
- Stability in SGD [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/09_SGD_stability.pdf)

### Lecture 8: Momentum and Adaptive SGD <br>
- Momentum SGD [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/10_ACC_SGD.pdf) [[Notes]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/notes_ch8_1.pdf) <br>
- AdaGrad; RMSProp; Adam [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/11_Adaptive_SGD.pdf) 

### Lecture 9: Midterm <br>

### Lecture 10: FlashAttention <br>
- Memory access cost; Kernal fusion; Flash attention [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/22_FlashAttention.pdf)

### Lecture 11: Block Coordinate Descent <br>
- Block coordinate descent; Coordinate friendly structure [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/14_CD.pdf)
- Block-wise training in LLMs [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/15_LISA.pdf)

### Lecture 12: Zeroth-Order Optimization <br>
- Finite difference; linear interpolation; sphere smoothing [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2025/ZO_GD.pdf) [[Notes]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2025/Notes_ZO.pdf)
- Memory-efficient zeroth-order optimization; Low-rank zeroth-order optimization [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2025/2025_LOZO.pdf)

### Lecture 13: Distributed Optimization <br>
- Data Parallelism; Pipeline Parallelism; Tensor Parallelism [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/19_Parallesm.pdf)
- Decentralized Learning [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/20_Decentralized.pdf)
- Communication Compression; Local Learning [[Slides]](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/teaching/DLOpt2024/21_Local_Compressed.pdf)
