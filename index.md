---
layout: page
title: ""
---

<img src="/images/KunYuan.jpg" alt="kunyuan" align="left" width="200"/>
<!-- <img src="https://github.com/kunyuan827/kunyuan827.github.io/raw/master/images/KunYuan.jpg" alt="kunyuan" align="left" width="200"/> -->
<!-- <img src="https://github.com/kunyuan827/kunyuan827.github.io/blob/master/assets/KunYuan.jpeg" alt="kunyuan" align="left" width="200"/> -->

<br>

&emsp; &emsp; &emsp; **Kun Yuan (袁 坤)** 

&emsp; &emsp; &emsp; Assistant Professor, Center for Machine Learning Research, Peking University

<!-- &emsp; Decision Intelligence Lab, DAMO Academy, Alibaba Group -->

&emsp; &emsp; &emsp; Email: kunyuan AT pku.edu.cn

&emsp; &emsp; &emsp; CV / [Google scholar](https://scholar.google.com/citations?user=aMnHLz4AAAAJ&hl=en) 

<br>

I am an Assistant Professor at [Center for Machine Learning Research (CMLR)](https://cmlr.pku.edu.cn/) in Peking University. 

My research lies in the theoretical and algorithmic foundations in optimization, signal processing, machine learning, and data science. I currently focus on the development of fast, scalable, reliable, and distributed algorithms with applications in large-scale optimization, deep neural network training, federated learning, and Internet of things.  

<!-- I was the recipient of several academic awards, including the prestigious 2017 IEEE Signal Processing Society Young Author Best Paper Award, and the 2017 ICCM Distinguished Paper Award.  -->

Before joining Peking University, I was a staff algorithm engineer in the [Decision Intelligence Lab](https://damo.alibaba.com/labs/decision-intelligence) in Alibaba (US) Group led by Prof. [Wotao Yin](https://wotaoyin.mathopt.com/). I completed my Ph.D. in Electrical and Computer Engineering from [University of California, Los Angeles (UCLA)](https://www.ucla.edu/) in 2019 under the supervision of Prof. [Ali H. Sayed](https://asl.epfl.ch/biography/). I was a visiting researcher at [École Polytechnique Fédérale de Lausanne (EPFL)](https://www.epfl.ch/en/) from 2018 January to 2018 June, and a research intern at [Microsoft Research Redmond](https://www.microsoft.com/en-us/research/group/deep-learning-group/) from 2018 June to 2018 October.

I was the recipient of the *2017 IEEE Signal Processing Society Young Author Best Paper Award* (joint with Dr. [Wei Shi](https://sites.google.com/view/wilburshi/home)), and the *2017 ICCM Distinguished Paper Award*.

<mark> We are hiring PostDocs and Undergraduate Research Interns!!! </mark> <br> 

<mark> Drop me an email if you are interested in machine learning, optimization, and AI systems. </mark> <br> 

<!-- <mark> 正在招收2024年暑期科研实习生。项目简介及要求请参看该文档 [SummerIntern.pdf](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/SummerIntern.pdf)。 </mark> <br> -->

<!-- <mark style="background-color: lightblue">我们课题组在2024 Spring还有一个轮转名额，欢迎叉院2023届博士生同学联系！</mark> <br> -->



### News
<!-- - [11/2022] We hosted *[2022 PKU Workshop on Operations Research and Machine Learning](http://conference.bicmr.pku.edu.cn/meeting/index?id=102)* online on Nov. 21 and Nov. 22. I gave a talk on *[DecentLaM: Decentralized Momentum SGD for Large-Batch Deep Training](https://arxiv.org/abs/2104.11981)*. Please check [Slides (on Github)](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/DecentLaM.pdf) or [Slides (on Baidu Wangpan)](https://pan.baidu.com/s/1-p7JBdI7ctIZ1-4VbwAL-Q?pwd=bjb6). -->

<!-- - <mark> We're hiring 2024 Summer Research Interns. Please check this [document](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/SummerIntern.pdf).</mark> <br> -->

<!-- - [06/2024] 正在招收2024年暑期实习生. 项目简介及要求请参看该 [文档](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/SummerIntern.pdf).  -->

- [01/2025] One paper is accepted to ICLR 2025. Congratulations to all collaborators!
  * *[Enhancing Zeroth-Order Fine-Tuning for Language Models with Low-Rank Structures](https://arxiv.org/pdf/2410.07698)* <br>

- [10/2024] A new paper *[Subspace Optimization for Large Language Models with Convergence Guarantees](https://arxiv.org/pdf/2410.11289)* is now available on arXiv. In this paper, we unexpectedly discover that GaLore does not always converge to the optimal solution and substantiate this finding with an explicit counterexample. We further propose a novel variant of GaLore that provably converges in stochastic optimization.

- [10/2024] A new paper *[Enhancing Zeroth-Order Fine-Tuning for Language Models with Low-Rank Structures](https://arxiv.org/pdf/2410.07698)* is now available on arXiv. In this work, we propose a low-rank zeroth-order gradient estimator and introduces a novel low-rank ZO algorithm to effectively fine-tune LLMs. It outperforms MeZO significantly.

- [10/2024] A new paper *[A Mathematics-Inspired Learning-to-Optimize Framework for Decentralized Optimization](https://arxiv.org/pdf/2410.01700)* is now available on arXiv. In this work, we present the first learning-to-optimize framework that surpasses state-of-the-art hand-crafted decentralized algorithms.

- [09/2024] One paper is accepted to NeurIPS 2024. Congratulations to my student Shuchen Zhu, Boao Kong, and all collaborators!
  * *[SPARKLE: A Unified Single-Loop Primal-Dual Framework for Decentralized Bilevel Optimization](https://openreview.net/pdf?id=g5DyqerUpX)* <br>

- [09/2024] I will be teaching a course on *[Optimization for Deep Learning](./dlopt2024)* in 2024 Fall. 

- [06/2024] I will give a 3-hour tutorial on *Efficient Optimization for Deep Learning* at *[Fudan University](https://www.fudan.edu.cn/)* on June 8th. Please check the *[slides](./talks)*.

- [05/2024] I will teach a short summer course titled *Efficient Optimization for Large Language Models* at *[Beijing Jiaotong University](https://www.bjtu.edu.cn/)* from July 7th to July 9th. It will be a condensed mix of my two regular classes *[Optimization for Deep Learning](./dlopt2023/)* and *[Large Language Models in Decision Intelligence](./llm2024)*. The syllabus is coming soon. 

- [05/2024] One paper is accepted to ICML 2024. Congratulations to my student Yutong He, Jie Hu, and all collaborators! 
  * *[Distributed Bilevel Optimization with Communication Compression](https://arxiv.org/pdf/2405.18858)* <br>
  
- [04/2024] My undergraduate students, [Ziheng Cheng](https://openreview.net/profile?id=~Ziheng_Cheng4) and Liyuan Liang, have been admitted to the UC Berkeley PhD Program. Additionally, Lujing Zhang has been admitted to the Carnegie Mellon University (CMU) PhD Program. Congratulations to all of them! We are currently hiring undergraduate research interns. We are committed to providing abundant resources and comprehensive instructions to support their involvement in cutting-edge research projects. <br>

- [04/2024] I will give a talk on [Asynchronous Diffusion Learning with Agent Subsampling and Local Updates](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/talk/ICASSP2014.pdf) at [IEEE ICASSP 2024]([https://groups.oist.jp/mlss](https://2024.ieeeicassp.org/program-schedule/)).

- [03/2024] I will server as an Area Chair for [NeurIPS 2024](https://neurips.cc/).

- [03/2024] I will give a tutorial lecture on Distributed Machine Learning at [MLSS 2024](https://groups.oist.jp/mlss). Lecture slides can be found at [Distributed Machine Learning: Part I](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/talk/DistributedML-PartI[Okinawa].pdf) and [Distributed Machine Learning: Part II](https://github.com/kunyuan827/kunyuan827.github.io/raw/master/resources/talk/DistributedML-Part2[Okinawa].pdf).

- [02/2024] I will be teaching a course on *[Large Language Models in Decision Intelligence](./llm2024)* in 2024 Spring. 

- [02/2024] A new paper *[Decentralized Bilevel Optimization over Graphs: Loopless Algorithmic Update and Transient Iteration Complexity](https://arxiv.org/pdf/2402.03167.pdf)* is on arXiv now. We have calrified the joint influence of network topology and data heterogeneity on decentralized bilevel optimization.
  
- [01/2024] One paper is accepted to ICLR 2024. Congratulations to my student Ziheng Cheng and all collaborators! 
  * *[Momentum Benefits Non-IID Federated Learning Simply and Provably](https://arxiv.org/pdf/2306.16504.pdf)* <br>  

- [12/2023] A new paper *[Towards Better Understanding the Influence of Directed Networks on Decentralized Stochastic Optimization](https://arxiv.org/pdf/2312.04928.pdf)* is on arXiv now. Surprisingly, we find that spectral gap is not enough to capture the influence of directed networks and the equilibrium skewness matters a lot! We also establish the lower bound for decentralized algorithms with clomun-stochastic mixing matrices. 

- [11/2023] We will organize a session on [Decentralized Optimization and Learning](https://css.paperplaza.net/conferences/conferences/CDC23/program/CDC23_ContentListWeb_1.html#wea05) in IEEE CDC 2023. 

- [11/2023] One paper is accepted by Signal Processing.
  * *[An Enhanced Gradient-Tracking Bound for Distributed Online Stochastic Convex Optimization](https://arxiv.org/abs/2301.02855)*

- [09/2023] A new paper *[Sharper Convergence Guarantees for Federated Learning with Partial Model Personalization](https://arxiv.org/abs/2309.17409)* is on arXiv now. We establish new state-of-the-art convergence rates for federated learning with partial model personalization!

- [09/2023] One paper is accepted to NeurIPS 2023.
  * *[Unbiased Compression Saves Communication in Distributed Optimization: When and How Much?](https://arxiv.org/abs/2305.16297)* <br>
  
  Congratulations to my student Yutong He on publishing his first paper! 

- [09/2023] I will be teaching a course on *[Optimization for Deep Learning](./dlopt2023/)* in 2023 Fall. 

- [09/2023] One paper is accepted by Journal of Machine Learning Research (JMLR).
  * *[Removing Data Heterogeneity Influence Enhances Network Topology Dependence of Decentralized SGD](https://arxiv.org/pdf/2105.08023.pdf)*


- [07/2023] Two papers are accepted to IEEE CDC 2023.
  * *[Achieving Linear Speedup with Network-Independent Learning Rates in Decentralized Stochastic Optimization](https://ieeexplore.ieee.org/abstract/document/10384058)*
  * *[On the Performance of Gradient Tracking with Local Updates](https://arxiv.org/abs/2210.04757)*
    
  Congratulations to my student Hao Yuan and my collaborator Edward Nguyen on publishing their first papers! 

- [06/2023] A new paper *[Momentum Benefits Non-IID Federated Learning Simply and Provably](https://arxiv.org/pdf/2306.16504.pdf)* is on arXiv now. An interesting message is that FedAvg can converge without data heterogeneity assumption when incorporating momentum!

- [05/2023] A new paper *[Unbiased Compression Saves Communication in Distributed Optimization: When and How Much?](https://arxiv.org/pdf/2305.16297.pdf)* is on arXiv now. 

- [05/2023] A new paper *[Lower Bounds and Accelerated Algorithms in Distributed Stochastic Optimization with Communication Compression](https://arxiv.org/abs/2305.07612)* is on arXiv now. Please also check [Slides (on Github)](/resources/KunYuan_OptimalCompression.pdf) or [Slides (on Baidu Wangpan)](https://pan.baidu.com/s/1q5ROxiIdkqTCiXkNJmJgqg?pwd=atfh) for this paper. Some preliminary results of this paper have been published in NeurIPS 2022, check [this paper](https://arxiv.org/pdf/2206.03665.pdf). 

- [04/2023] Two papers are accepted to ICML 2023. 

  * *[DSGD-CECA: Decentralized SGD with Communication-Optimal Exact Consensus Algorithm](https://arxiv.org/pdf/2306.00256.pdf)*
  * *[AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation](https://arxiv.org/pdf/2304.12566.pdf)*
 
- [02/2023] One paper *[BEVHeight: A Robust Framework for Vision-based Roadside 3D Object Detection](https://arxiv.org/abs/2303.08498)* is accepted to CVPR 2023.

- [01/2023] A new paper *[An Enhanced Gradient-Tracking Bound for Distributed Online Stochastic Convex Optimization](https://arxiv.org/abs/2301.02855)* is on arXiv now. We establish enhanced rates for Gradient Tracking methods under the online stochastic convex settings.

- [11/2022] I gave a talk in *[BICMR](https://bicmr.pku.edu.cn/)* on *Accelerating Decentralized SGD with Sparse and Effecitve Topologies*, which includes our rescent results on *[Exponential Graphs](https://arxiv.org/abs/2110.13363)*, *[EquiToPo Graphs](https://arxiv.org/abs/2210.07881)*, and *[BlueFog](https://arxiv.org/abs/2111.04287)*. Please check [Slides (on Github)](/resources/Topologies_for_decentralized_deep_learning.pdf) or [Slides (on Baidu Wangpan)](https://pan.baidu.com/s/1UKEEPiISeNfxySg8-DJe2w?pwd=8849).

- [11/2022] We hosted *[2022 PKU Workshop on Operations Research and Machine Learning](http://conference.bicmr.pku.edu.cn/meeting/index?id=102)* online on Nov. 21 and Nov. 22. I gave a talk on *[DecentLaM: Decentralized Momentum SGD for Large-Batch Deep Training](https://arxiv.org/abs/2104.11981)*. Please check [Slides (on Github)](/resources/DecentLaM.pdf) or [Slides (on Baidu Wangpan)](https://pan.baidu.com/s/1-p7JBdI7ctIZ1-4VbwAL-Q?pwd=bjb6).

<!-- - [10/2022] Our paper *[Optimal Complexity in Non-Convex Decentralized Learning over Time-Varying Networks](https://arxiv.org/abs/2211.00533)* was accepted to NeurIPS 2022 Workshop on [Optimization for Machine Learning](https://opt-ml.org/index.html). -->

- [09/2022] Three papers are accepted to NeurIPS 2022. 

  * [*Revisiting Optimal Convergence Rate for Smooth and Non-convex Stochastic Decentralized Optimization*](https://arxiv.org/pdf/2210.07863.pdf)
  * [*Communication-Efficient Topologies for Decentralized Learning with O(1) Consensus Rate*](https://arxiv.org/pdf/2210.07881.pdf)
  * [*Lower Bounds and Nearly Optimal Algorithms in Distributed Learning with Communication Compression*](https://arxiv.org/pdf/2206.03665.pdf)
  

- [09/2022] Prof. Wotao Yin was invited to give a keynote talk on our recent work *[Lower Bounds and Nearly Optimal Algorithms in Distributed Learning with Communication Compression](https://arxiv.org/abs/2206.03665)* in the [CrossFL 2022](https://crossfl2022.github.io/) workshop. Please check the [slides](https://crossfl2022.github.io/presentations/OptimalCompression.pdf) and the [Youtube video](https://youtu.be/0mV85uGMpXA?t=19516).  

<!-- I received my M. E. degree from [University of Science and Technology of China (USTC)](https://en.ustc.edu.cn/) in 2014 supervised by Prof. [Qing Ling](https://scholar.google.com/citations?user=u70vRDYAAAAJ&hl=en), and B. E. degree from [Xidian University](https://en.xidian.edu.cn/) in 2011.  -->

<!-- ### Academic Awards

- 2017 IEEE Signal Processing Society Young Author Best Paper Award [[Awardee list]](https://signalprocessingsociety.org/sites/default/files/uploads/get_involved/awards/Young_Author_Best_Paper.pdf) [[News]](https://sist.ustc.edu.cn/2018/0423/c5146a257808/page.htm) <br>

- 2017 ICCM Distinguished Paper Award -->

